# Data Card Component System Brainstorming

## Goal
Transition from a single, monolithic prompt generating all custom React/Recharts code for each paper to a system using pre-defined, reusable visualization *components*. An LLM will dynamically construct a dashboard for each paper by selecting appropriate components for different sections (tabs) and providing the necessary data and text content.

## Current Process Recap
1.  **Input:** arXiv paper content + `prompts/react_prompts.py::PDATA_CARD_USER_PROMPT`.
2.  **LLM Output:** A summary string and a single `<script>` block containing all React/Recharts code (color definitions, chart components, card components, dashboard layout, render call).
3.  **Rendering:** The generated `<script>` is embedded into `utils/data_cards.py::html_template`, which provides common layout components (`Card`, `Tabs`) and basic HTML structure.

## Proposed New Process (Component-Based)
1.  **Define Components:** Create definitions for individual, reusable chart/visualization components (e.g., `BarChartComponent`, `LineChartComponent`, `RadarChartComponent`, `TreemapComponent`, `PieChartComponent`, `AreaChartComponent`, `ScatterPlotComponent`, `TextComponent`, `ListComponent`). Each component definition includes its purpose, required Recharts elements, the specific data structure (`parameter_schema`) it expects, and sample data (`sample_filled_parameters`).
2.  **LLM Task:**
    *   Input: arXiv paper content + descriptions/schemas of available components.
    *   Process: Read paper, analyze content. For each of the ~5 tabs required in the standard dashboard layout:
        *   Determine the key finding/information to present.
        *   Select the *most suitable component* type from the available list (aiming for diversity across tabs).
        *   Extract/generate the data/text conforming to the chosen component's `parameter_schema`.
        *   Compose a title, descriptive paragraph, and an optional note for the tab.
    *   Output:
        *   `summary`: string (Concise paper summary).
        *   `dashboard_structure`: JSON object or array describing the content for *each tab*. Each entry should specify:
            *   `tab_id`: (e.g., `"tab1"`, `"conclusion"`)
            *   `title`: string (LLM-generated title for the tab)
            *   `description`: string (LLM-generated paragraph for the tab)
            *   `note`: string (LLM-generated optional note for the tab)
            *   `chosen_component_id`: string (Identifier of the selected component, e.g., `"bar_chart_v1"`)
            *   `filled_parameters`: JSON object (Data and text extracted/generated by the LLM, structured according to the `parameter_schema` of the `chosen_component_id`).
3.  **Backend Rendering:**
    *   Input: LLM Output (`summary`, `dashboard_structure`).
    *   Process:
        *   Load a master React/Recharts script. This script contains:
            *   Definitions for *all* available component types (e.g., `BarChartComponent`, `LineChartComponent`, etc.), designed to be parameterized.
            *   The standard dashboard layout structure (using `Tabs`, `FindingCard` from the HTML template).
        *   Generate the final `<script>` content dynamically:
            *   Pass the `dashboard_structure` JSON to the master script (e.g., via `window` object).
            *   The script iterates through the `dashboard_structure` array.
            *   For each item, it renders a tab containing a `FindingCard`.
            *   Inside the `FindingCard`, it dynamically instantiates the React component corresponding to the `chosen_component_id`, passing the `filled_parameters` as props.
        *   Embed the `summary` and the generated/master script into the `utils/data_cards.py::html_template`.

## Component Design Considerations

### 1. Component Definitions (How to define them?)
*   **Location:** Store definitions in a dedicated directory, e.g., `templates/components/`.
*   **Format:** JSON seems suitable for defining the metadata and schema of each component.
*   **Content per Component File (e.g., `templates/components/bar_chart_v1.json`):**
    *   `component_id`: Unique identifier (e.g., `"bar_chart_v1"`).
    *   `name`: Human-readable name (e.g., `"Bar Chart (Comparative)"`).
    *   `description`: Explanation for the LLM (e.g., `"Use to compare numerical values across distinct categories or groups. Good for showing performance differences, resource usage, etc."`).
    *   `required_recharts_components`: List needed by the React implementation (e.g., `["ResponsiveContainer", "BarChart", "CartesianGrid", "XAxis", "YAxis", "Tooltip", "Legend", "Bar"]`).
    *   `parameter_schema`: JSON schema defining the structure of the `filled_parameters` the LLM must provide for *this specific component*.
    *   `sample_filled_parameters`: (Optional but Recommended) A concrete JSON object instance matching the `parameter_schema`, usable for testing and as an example for the LLM.

### 2. Parameter Schemas (Examples)
*   **Bar Chart (`bar_chart_v1.json`):**
    ```json
    "parameter_schema": {
      "type": "object",
      "properties": {
        "data": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "category": { "type": "string", "description": "Label for the X-axis category" },
              "value1": { "type": "number", "description": "First value to plot for this category" },
              "value1_name": { "type": "string", "description": "Label for the first value series (legend)" },
              "value2": { "type": "number", "description": "Optional second value to plot" },
              "value2_name": { "type": "string", "description": "Optional label for the second value series" }
            },
            "required": ["category", "value1", "value1_name"]
          }
        }
      },
      "required": ["data"]
    },
    "sample_filled_parameters": {
      "data": [
        { "category": "Metric A", "value1_name": "Method 1", "value1": 85, "value2_name": "Method 2", "value2": 78 },
        { "category": "Metric B", "value1_name": "Method 1", "value1": 92, "value2_name": "Method 2", "value2": 95 }
      ]
    }
    ```
*   **Treemap (`treemap_v1.json`):**
    ```json
    "parameter_schema": {
      "type": "object",
      "properties": {
        "data": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "name": { "type": "string", "description": "Label for the treemap segment" },
              "size": { "type": "number", "description": "Numerical value determining the segment size" }
            },
            "required": ["name", "size"]
          }
        }
      },
      "required": ["data"]
    },
    "sample_filled_parameters": {
      "data": [
        { "name": "Component X", "size": 40 },
        { "name": "Component Y", "size": 30 },
        { "name": "Component Z", "size": 30 }
      ]
    }
    ```
*   **Simple Text (`text_v1.json`):**
    ```json
    "parameter_schema": {
      "type": "object",
      "properties": {
        "content": { "type": "string", "description": "The main text content to display." }
      },
      "required": ["content"]
    },
    "sample_filled_parameters": {
      "content": "This component displays plain text content provided by the LLM, suitable for qualitative findings or explanations."
    }
    ```

### 3. LLM Interaction
*   The new LLM prompt needs to clearly outline the component selection and data filling task for each tab.
*   It must provide the `name` and `description` for each available component.
*   It must specify the required output format (`summary` and `dashboard_structure` JSON).
*   It needs to instruct the LLM to consult the `parameter_schema` when formatting the `filled_parameters` for the chosen component (potentially using the `sample_filled_parameters` as guidance).
*   Encourage the LLM to select a diverse set of components across the tabs.

### 4. Master React Script
*   This script won't be generated by the LLM but will be a static asset (or embedded string in Python), e.g., `assets/master_dashboard.js`.
*   It needs implementations for *all* defined component types (e.g., `BarChartComponent`, `LineChartComponent`, etc.). These React components will expect props matching the structure defined in the corresponding `parameter_schema`.
*   It will contain the main dashboard layout logic that reads the `dashboard_structure` JSON and dynamically renders the correct components in the correct tabs.
*   Needs access to a shared color palette (defined perhaps in the script itself or passed alongside the data).

### 5. Color Palettes
*   Define reusable color palettes, perhaps in `templates/palettes.json`.
*   The master script can load/use a specific palette (e.g., the LLM could potentially suggest a palette, or a default is used).

### 6. Testing Harness
*   Create a simple HTML file (e.g., `templates/components/test_harness.html`) that loads the *master React script* (`assets/master_dashboard.js`).
*   This harness should allow specifying a `component_id` (e.g., via URL parameter or simple dropdown) and render *only* that component, feeding it the `sample_filled_parameters` from its corresponding JSON definition file.
*   This facilitates isolated testing and visual verification of each component during development.

## Revised Next Steps [ ]
1.  [ ] Finalize the list of initial component types (e.g., Bar, Line, Radar, Treemap, Pie, Area, Scatter, Text, List) aiming for variety without excessive complexity. Create their JSON definition files (`templates/components/*.json`) including `parameter_schema` and `sample_filled_parameters`.
2.  [ ] Create `templates/palettes.json` with one or two color palette definitions.
3.  [ ] Draft the new LLM prompt (`prompts/react_component_prompt.py`?) explaining the component selection task (encouraging diversity) and the required JSON output (`summary`, `dashboard_structure`).
4.  [ ] Design and implement the static Master React Script (`assets/master_dashboard.js`?) containing:
    *   React component definitions for all component types.
    *   Logic to parse input data (`dashboard_structure`, `palette`) and render the dynamic dashboard.
    *   `ReactDOM.render()` call.
5.  [ ] Create the component test harness (`templates/components/test_harness.html`) capable of rendering individual components using their sample data via the master script.
6.  [ ] Modify `utils/data_cards.py::generate_data_card_html`:
    *   Load component definitions (for the LLM prompt).
    *   Load the master React script content.
    *   Call the LLM with the new prompt.
    *   Receive and potentially validate the LLM's JSON output (`summary`, `dashboard_structure`).
    *   Prepare data for the master script (e.g., serialize `dashboard_structure` and palette choice to JSON).
    *   Embed the summary, data JSON, and master script content into the `html_template`.
7.  [ ] Create the `templates/components/` and `assets/` directories.
8.  [ ] Update `STRUCTURE.md` to reflect new files/directories.

## Potential Challenges
*   Ensuring LLM consistently selects appropriate components and provides data matching the `parameter_schema`.
*   Designing flexible React components that handle potential variations in LLM-provided data gracefully.
*   Managing the complexity of the master React script as more component types are added.

This component-based approach seems more robust and flexible. Let's proceed with this revised plan. 